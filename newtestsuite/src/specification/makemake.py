import os
import tuples

######################################################################
# Utility functions
######################################################################
#

def uniq(lst):
	return reduce(lambda l, i: ((i not in l) and l.append(i)) or l, lst, [])

info = {}
def read_tuples(tuplefile):
	f = open(tuplefile)
	info['platforms'] = tuples.parse_platforms(f.readline())
	info['languages'] = tuples.parse_languages(f.readline())
	info['compilers'] = tuples.parse_compilers(f.readline())
	info['mutators'] = tuples.parse_mutators(f.readline())
	info['mutatees'] = tuples.parse_mutatees(f.readline())
	info['tests'] = tuples.parse_tests(f.readline())
	info['rungroups'] = tuples.parse_rungroups(f.readline())
# 	info['exception_types'] = tuples.parse_exception_types(f.readline())
	info['exception_types'] = None
# 	info['exceptions'] = tuples.parse_exceptions(f.readline())
	info['exceptions'] = None
	info['objects'] = tuples.parse_object_files(f.readline())
	f.close()

def extension(filename):
	ext_ndx = filename.rfind('.')
	return filename[ext_ndx:]

def replace_extension(name, ext):
	dot_ndx = name.rfind('.')
	return name[:dot_ndx] + ext

# Get the name of the language for the given file.  If more than one
# is possible, I don't really know what to do...  Return a list of all
# the possibilities with compilers on the current platform?
def get_file_lang(filename):
	ext = extension(filename)
	langs = filter(lambda x: ext in x['extensions'], info['languages'])
	# We have a list of all languages which match the extension of the file
	# Filter out all of those languages for which there is no compiler on this
	# platform:
	#  Find the compilers available on this platform
	platform = os.environ.get('PLATFORM')
	comps = filter(lambda x: platform in info['compilers'][x]['platforms'],
				   info['compilers'])
	#  Get a list of all the languages supported by those compilers
	supported_langs = map(lambda x: info['compilers'][x]['languages'],
						  info['compilers'])
	supported_langs = reduce(lambda x,y:x+y, supported_langs)
	supported_langs = uniq(supported_langs)
	#  Remove all languages from langs that aren't in supported_langs
	langs = filter(lambda x: x['name'] in supported_langs, langs)
	if len(langs) > 1:
		return langs
	else:
		return langs[0]

def compiler_count(lang):
	plat = os.environ.get('PLATFORM')
	return len(filter(lambda x: lang in info['compilers'][x]['languages']
					        and plat in info['compilers'][x]['platforms']
					  , info['compilers']))

def find_platform(pname):
	plist = filter(lambda p: p['name'] == pname, info['platforms'])
	if len(plist) == 0:
		return None
	else:
		return plist[0]

def mutatee_binary(mutatee):
	# Returns standard name for the solo mutatee binary for this mutatee
	return "%s.mutatee_solo_%s_%s_%s" % (mutatee['name'],
										 info['compilers'][mutatee['compiler']]['executable'],
										 mutatee['abi'],
										 mutatee['optimization'])
#
######################################################################


######################################################################
# make.mutators.gen
######################################################################
#

def print_mutators_list(out, mutator_dict):
	out.write("######################################################################\n")
	out.write("# A list of all the mutators to be compiled\n")
	out.write("######################################################################\n\n")
	out.write("MUTATORS = ")
	for m in mutator_dict:
		out.write("%s " % (m['name']))
	out.write("\n\n")
	out.write("OBJS_ALL_MUTATORS = ")
	for m in mutator_dict:
		out.write("%s.o " % (m['name']))
	out.write("\n\n")

	# Now we'll print out a rule for each mutator..
	for m in mutator_dict:
		# FIXME Don't hardcode the '.so' or '.o' extension here
		# FIXME Don't hardcode $(LIBTESTSUITE)
		out.write("%s.so: " % (m['name']))
		# TODO Loop through the files listed in this mutator's source list and
		# add object files corresponding to each to the list of dependencies
		for s in m['sources']:
			# Print out the object file for this source file
			# FIXME Don't use hardcoded '.o' extension
			out.write("%s.o " % s[0:-len(extension(s))])
		out.write("$(OBJS_FORALL_MUTATORS) $(DEPENDDIR)/%s.dep $(LIBTESTSUITE)\n" % (m['name']))

		# FIXME Make this one better too.  Right now it's copied straight from
		# make.module.tmpl
		out.write("\t$(CXX) -o $@ -shared $(filter %.o,$^) $(MUTATOR_SO_LDFLAGS) $(LIBDIR) $(LIBS) $(LDFLAGS)\n")
		out.write("ifndef NO_OPT_FLAG\n")
		out.write("ifdef STRIP_SO\n")
		out.write("\t$(STRIP_SO) $@\n")
		out.write("endif\n")
		out.write("endif\n\n")


def write_make_mutators_gen(filename, tuplefile):
	read_tuples(tuplefile)
	mutator_dict = info['mutators']
	header = """
# This file is automatically generated by the Dyninst testing system.
# For more information, see core/testsuite/src/specification/makemake.py

"""
	# FIXME Fix this so it doesn't hardcode the '.so' extension
	rest = """
# Create shared library names from the mutator test names
MUTATORS_SO += $(addsuffix .so,$(MUTATORS))

# And a rule to build all of the libraries
.PHONY: mutators
mutators: $(MUTATORS_SO)

"""
	out = open(filename, "w")
	out.write(header)
	print_mutators_list(out, mutator_dict)
	out.write(rest)
	out.close()

#
######################################################################

######################################################################
# test_info_new.gen.C
######################################################################
#

def write_test_info_new_gen(filename, tuplefile):
	header = """/* This file automatically generated from test specifications.  See
 * specification/spec.pl and specification/makemake.py
 */

#include "test_info_new.h"

// The constructor for TestInfo
TestInfo::TestInfo(unsigned int i, const char *iname, const char *imrname,
                   const char *isoname, const char *ilabel)
  : index(i), name(iname), mutator_name(imrname), soname(isoname),
    label(ilabel), mutator(NULL), disabled(false), enabled(false)
{
}

// Constructor for RunGroup, with an initial test specified
RunGroup::RunGroup(char *mutatee_name, start_state_t state_init,
                   create_mode_t attach_init, bool ex, TestInfo *test_init)
  : mutatee(mutatee_name), state(state_init), useAttach(attach_init),
    customExecution(ex)
{
  tests.push_back(test_init);
}

// Constructor for RunGroup with no initial test specified
RunGroup::RunGroup(char *mutatee_name, start_state_t state_init,
                   create_mode_t attach_init, bool ex)
  : mutatee(mutatee_name), state(state_init), useAttach(attach_init),
    customExecution(ex)
{
}

// RunGroup's destructor clears its vector of tests
RunGroup::~RunGroup() {
//  while (tests.size() > 0) {
//    delete tests[0];
//    tests.erase(tests.begin());
//  }
}

// We define one global variable to store the list of run groups that we'll run
// std::vector<RunGroup *> tests;

"""
	read_tuples(tuplefile)
	compilers = info['compilers']
	rungroups = info['rungroups']
	out = open(filename, "w")
	out.write(header)
	print_initialize_mutatees(out, rungroups, compilers)
	out.close()

# Return the name of the mutatee executable for this rungroup
def mutatee_filename(rungroup, compilers):
	if rungroup['mutatee'] == 'none':
		retval = ""
	else:
		retval = "%s.mutatee_solo_%s_%s_%s" % (rungroup['mutatee'],
											   info['compilers'][rungroup['compiler']]['executable'],
											   rungroup['abi'],
											   rungroup['optimization'])
	return retval

# Return the name of the mutator for this test
def test_mutator(testname):
	testobj = filter(lambda t: t['name'] == testname, info['tests'])
	if len(testobj) >= 1:
		testobj = testobj[0]
	else:
		# TODO Handle this case better
		testobj = None
	if testobj != None:
		mrname = testobj['mutator']
	else:
		mrname = None
	return mrname

def print_initialize_mutatees(out, rungroups, compilers):
	header = """
// Now we insert the test lists into the run groups
void initialize_mutatees(std::vector<RunGroup *> &tests) {
  unsigned int group_count = 0;
  // Keep track of which element each test is, for later use with the resumelog
  unsigned int test_count;
  RunGroup *rg;
"""
	out.write(header)
	# TODO Change these to get the string conversions from a tuple output
	for group in rungroups:
		compiler = info['compilers'][group['compiler']]
		if compiler['presencevar'] != 'true':
			out.write("#ifdef %s\n" % (compiler['presencevar']))
		mutateename = mutatee_filename(group, compilers)
		out.write('  test_count = 0;\n')
		out.write('  rg = new RunGroup("%s", ' % (mutateename))
		if group['start_state'] == 'stopped':
			out.write('STOPPED, ')
		elif group['start_state'] == 'running':
			out.write('RUNNING, ')
		else: # Assuming 'selfstart'
			out.write('SELFSTART, ')
		if group['run_mode'] == 'createProcess':
			out.write('CREATE, ')
		else: # Assuming 'useAttach'
			out.write('USEATTACH, ')
		if group['groupable'] == 'true':
			out.write('false') # !groupable
		else:
			out.write('true') # !groupable
		out.write(');\n')
		for test in group['tests']:
			# Set the tuple string for this test
			# FIXME Need to account for MABI somehow.. Different compiler?
			# (<test>, <mutatee compiler>, <mutatee optimization>, <create mode>)
			# I need to get the mutator that this test maps to..
			mutator = test_mutator(test)
			ts = "{test: %s, mutator: %s, mutatee: %s, compiler: %s, mutatee_abi: %s, optimization: %s, run_mode: %s, grouped: %s}" % (test, mutator, group['mutatee'], group['compiler'], group['abi'], group['optimization'], group['run_mode'], 'false')
			out.write('  rg->tests.push_back(new TestInfo(test_count++, "%s", "%s", "%s.so", "%s"));\n' % (test, mutator, mutator, ts))
		out.write('  rg->index = group_count++;\n')
		out.write('  tests.push_back(rg);\n')
		# Close compiler presence #ifdef
		if compiler['presencevar'] != 'true':
			out.write("#endif // defined(%s)\n" % (compiler['presencevar']))
	out.write('}\n')

#
##########

######################################################################
# solo_mutatee_init.gen.c
######################################################################
#

def write_solo_mutatee_init_gen(filename, tuplefile):
	def tests(mutatee):
		# Returns a list of the unique tests that use this mutatee
		return uniq(reduce(lambda x, y: x + y,
						   map(lambda r: r['tests'],
							   filter(lambda r: r['mutatee'] == mutatee['name'],
									  info['rungroups']))))
	def testcount(mutatee):
		# Returns the count of unique tests that use this mutatee
		return len(uniq(reduce(lambda x, y: x + y,
							   map(lambda r: r['tests'],
								   filter(lambda r: r['mutatee'] == mutatee['name'],
										  info['rungroups'])))))

	header = """#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#include "mutatee_call_info.h"

/* Allocate space in the info structure for size tests */
int alloc_info(mutatee_info_t *info, int size) {
  if (NULL == info) {
    goto _alloc_info_unwind_none;
  }

  info->funcs = malloc(size * sizeof (mutatee_call_info_t));
  if (NULL == info->funcs) {
    goto _alloc_info_unwind_funcs;
  }
  info->runTest = malloc(size * sizeof (int));
  if (NULL == info->runTest) {
    goto _alloc_info_unwind_runTest;
  }
  info->passedTest = malloc(size * sizeof (int));
  if (NULL == info->passedTest) {
    goto _alloc_info_unwind_passedTest;
  }

  return 0; /* Success */

 _alloc_info_unwind_all:
  free(info->passedTest);
 _alloc_info_unwind_passedTest:
  free(info->runTest);
 _alloc_info_unwind_runTest:
  free(info->funcs);
 _alloc_info_unwind_funcs:
 _alloc_info_unwind_none:
  return -1; /* Error */
}

"""

	out = open(filename, 'w')
	read_tuples(tuplefile)
	out.write(header)
	out.write("/* External declarations for mutatee-side test functions */\n")
	for m in uniq(map(lambda m: m['name'], info['mutatees'])):
		out.write("extern int %s_mutateeTest();\n" % (m))
	out.write("\n")
	out.write("""/* Initialize the mutatee info structure */
int init_tests(char *mutatee, mutatee_info_t *info) {
  if ((NULL == mutatee) || (NULL == info)) {
    return -1; /* Error */
  }

""")
	for m in info['mutatees']:
		n = mutatee_binary(m)
		out.write("  if (0 == strcmp(mutatee, \"%s\")) {\n" % (n))
		out.write("    /* set up info structure for %s */\n" % (n))
		out.write("    if (alloc_info(info, 1)) {\n")
		out.write("      return -1; /* Error */\n")
		out.write("    }\n")
		# This is the solo mutatee init file; I only need to be concerned about
		# single-test mutatees
		out.write("    info->funcs[0].testname = \"%s\";\n" % (m['name']))
		out.write("    info->funcs[0].func = %s_mutateeTest;\n" % (m['name']))
		out.write("    info->funcs[0].grouped = SOLO;\n")
		out.write("    info->runTest[0] = 1;\n")
		out.write("    info->passedTest[0] = 0;\n")
		out.write("    info->size = 1;\n")
		out.write("    info->groupable = ")
		if (m['groupable'] == 'true'):
			out.write("1;\n")
		else:
			out.write("0;\n")
		out.write("    return 0;\n")
		out.write("  } else")
	out.write(" {\n")
	out.write("    return -1;\n")
	out.write("  }\n")
	out.write("}\n")

#
######################################################################

######################################################################
# make.solo_mutatee.gen
######################################################################
#

def collect_mutatee_comps(mutatees):
	comps = []
	for m in mutatees:
		if m['compiler'] != '' and m['compiler'] not in comps:
			comps.append(m['compiler'])
	return comps

# Print makefile variable initializations for all the compilers used for
# makefiles on this platform
def print_mutatee_comp_defs(out):
	out.write("# Define variables for our compilers, if they aren't already defined\n")
	pname = os.environ.get('PLATFORM')
	# TODO Check that we got a string
	comps = filter(lambda c: c != ''
				             and pname in info['compilers'][c]['platforms'],
				   info['compilers'])
	for c in comps:
		if info['compilers'][c]['presencevar'] != 'true':
			out.write("ifdef %s\n" % (info['compilers'][c]['presencevar']))
		out.write('M_%s ?= %s\n' % (info['compilers'][c]['defstring'], info['compilers'][c]['executable']))
		if info['compilers'][c]['presencevar'] != 'true':
			out.write("endif\n")
	out.write('\n')

def print_mutatee_rules(out, mutatees, compiler):
	mut_names = map(lambda x: mutatee_binary(x), mutatees)
	out.write("######################################################################\n")
	out.write("# Mutatees compiled with %s\n" % (mutatees[0]['compiler']))
	out.write("######################################################################\n\n")
	if compiler['presencevar'] != 'true':
		out.write("ifdef %s\n" % (compiler['presencevar']))
	out.write("SOLO_MUTATEES_%s = " % (compiler['defstring']))
	for m in mut_names:
		out.write("%s " % (m))
	out.write('\n')
	if compiler['presencevar'] != 'true':
		out.write("endif\n")
	out.write("\n")
	#out.write("# Define the mutatee compiler if it isn't already defined\n")
	#out.write("# (This may not be necessary)\n")
	#out.write("M_%s ?= %s\n\n" % (compiler['defstring'], compiler['executable']))
	out.write("# Now a list of rules for compiling the mutatees with %s\n\n"
			  % (mutatees[0]['compiler']))

	pname = os.environ.get('PLATFORM')
	platform = find_platform(pname)

	# Write rules for building the mutatee executables from the object files
	for (m, n) in zip(mutatees, mut_names):
		out.write("%s: " % (n))
		for f in m['preprocessed_sources']:
			# List all the compiled transformed source files
			# I need to futz with the compiler here to make sure it's correct..
			# FIXME This next line may end up arbitrarily picking the first
			# language from a list of more than one for an extension
			lang = filter(lambda l: extension(f) in l['extensions'],
						  info['languages'])[0]['name']
			if (lang in compiler['languages']):
				out.write("%s " % (replace_extension(f, "_solo_%s_%s_%s.o"
													 % (info['compilers'][m['compiler']]['executable'],
														m['abi'],
														m['optimization']))))
			else: # Preprocessed file compiled with auxilliary compiler
				pname = os.environ.get('PLATFORM')
				# TODO Check that we got a string..
				platform = find_platform(pname)
				# TODO Check that we retrieved a platform object
				aux_comp = platform['auxilliary_compilers'][lang]
				# TODO Verify that we got a compiler
				out.write("%s " % (replace_extension(f, "_solo_%s_%s_%s.o"
													 % (aux_comp, m['abi'],
														m['optimization']))))
		# TODO Let's grab the languages used in the preprocessed sources, and
		# save them for later.  We use this to determine which raw sources get
		# compiled with the same options as the preprocessed ones, in the case
		# of a compiler that is used for more than one language (e.g. GCC in
		# tests test1_35 or test_mem)

		# FIXME I'm doing this wrong: the compiler for preprocessed files might
		# not be the compiler that we're testing..
		# Get the compiler..
		maincomp_langs = uniq(info['compilers'][m['compiler']]['languages'])
		pp_langs = uniq(map(lambda x: get_file_lang(x)['name'], m['preprocessed_sources']))
		# So we want to print out a list of object files that go into this
		# mutatee.  For files that can be compiled with m['compiler'], we'll
		# use it, and compile at optimization level m['optimization'].  For
		# other files, we'll just use the appropriate compiler and not worry
		# about optimization levels?
		for f in m['raw_sources']:
			# Figure out whether or not this file can be compiled with
			# m['compiler']
			lang = get_file_lang(f)
			if type(lang) == type([]):
				# FIXME I need to handle this better.  On our Unix platforms,
				# .s files can be assembled by multiple compilers, and can
				# contain different assembly languages..
				lang = lang[0] # BUG This may cause unexpected behavior if more
				               # than one language was returned
			if lang['name'] in maincomp_langs:
				# This file is compiled with the main compiler for this mutatee
				out.write("%s " % (replace_extension(f, "_%s_%s_%s.o"
													 % (info['compilers'][m['compiler']]['executable'],
														m['abi'],
														m['optimization']))))
			else:
				# This file is compiled with an auxilliary compiler
				# Find the auxilliary compiler for this language on this
				# platform
				# BUG This assumes that there is only one possible auxilliary
				# compiler for a language ending with the extension of interest
				# on the platform
				aux_comp = platform['auxilliary_compilers'][lang['name']]
				out.write("%s " % (replace_extension(f, '_%s_%s_none.o' %
													 (aux_comp, m['abi']))))
# 		for f in filter(lambda x: extension(x) not in ['.s', '.asm'], m['raw_sources']):
# 			# List all the compiled raw source files
# 			out.write("%s " % (replace_extension(f, "_%s_%s.o" % (m['compiler'], m['optimization']))))
# 		# TODO Fix this to use the correct compiler.  This block can actually be
# 		# removed / folded in to the block above once I remove the assumption
# 		# that all the files are being compiled with the default "mutatee
# 		# compiler" for this mutatee.
# 		for f in filter(lambda x: extension(x) in ['.s', '.asm'], m['raw_sources']):
# 			# Then list all the "compiled" assembly files
# 			out.write("%s " % (replace_extension(f, '.o')))
		# FIXME Check whether the current compiler compiles C files and if not
		# then use the aux compiler for this platform for the mutatee driver
		# object.
		if 'c' in info['compilers'][m['compiler']]['languages']:
			out.write("mutatee_driver_solo_%s_%s.o\n" % (info['compilers'][m['compiler']]['executable'],
														 m['abi']))
		else:
			# Get the aux compiler for C on this platform and use it
			aux_c = find_platform(os.environ.get('PLATFORM'))['auxilliary_compilers']['c']
			out.write("mutatee_driver_solo_%s_%s.o\n" % (aux_c, m['abi']))
		out.write("\t$(M_%s) -o $@ $(filter %%.o,$^) %s %s " % (compiler['defstring'], compiler['flags']['link'], compiler['abiflags'][platform['name']][m['abi']]))
		for l in m['libraries']:
			# Need to include the required libraries on the command line
			# FIXME Use a compiler-specific command-line flag instead of '-l'
			out.write("-l%s " % (l))
		out.write('\n')

# Prints all the special object file compile rules for a given compiler
# FIXME This doesn't deal with preprocessed files!
def print_special_object_rules(compiler, out):
	out.write("\n# Exceptional rules for mutatees compiled with %s\n\n"
			  % (compiler))
	objects = filter(lambda o: o['compiler'] == compiler, info['objects'])
	for o in objects:
		# TODO Print a rule to build this object file
		# TODO Convert the main source file name to an object name
		#  * Crap!  I don't know if this is a preprocessed file or not!
		#  * This should be okay soon; I'm removing the proprocessing stage..
		platform = os.environ.get("PLATFORM")
		ofileext = find_platform(platform)['filename_conventions']['object_suffix']
		ofilename = o['object'] + ofileext
		out.write("%s: " % (ofilename))
		for s in o['sources']:
			out.write("../src/%s " % (s))
		for i in o['intermediate_sources']:
			out.write("%s " % (i))
		for d in o['dependencies']:
			out.write("%s " % (d))
		out.write("\n")
		out.write("\t$(M_%s) $(SOLO_MUTATEE_DEFS) " % (info['compilers'][compiler]['defstring']))
		for f in o['flags']:
			out.write("%s " % (f))
		out.write("-o $@ %s " % info['compilers'][compiler]['parameters']['partial_compile'])
		for s in o['sources']:
			out.write("../src/%s " % (s))
		for i in o['intermediate_sources']:
			out.write("%s " % (i))
		out.write("\n")
	out.write("\n")

def print_generic_rules(c, out):
	out.write("\n# Generic rules for %s's mutatees and varying optimization levels\n" % (c))
	compiler = info['compilers'][c]
	platform = find_platform(os.environ.get('PLATFORM'))
	for abi in platform['abis']:
		for o in compiler['optimization']:
			# Rules for compiling source files to .o files
			# TODO Replace this code generation with language neutral code
			# generation
			if 'c' in compiler['languages']:
				out.write("%%_mutatee_solo_%s_%s_%s.o: %%_solo_me.c\n"
						  % (info['compilers'][c]['executable'], abi ,o))
				out.write("\t$(M_%s) $(SOLO_MUTATEE_DEFS) %s %s %s %s -o $@ -c $<\n"
						  % (compiler['defstring'],
							 compiler['flags']['std'],
							 compiler['flags']['mutatee'],
							 compiler['abiflags'][platform['name']][abi],
							 compiler['optimization'][o]))
				out.write("%%_%s_%s_%s.o: ../src/%%.c\n" % (info['compilers'][c]['executable'], abi, o))
				out.write("\t$(M_%s) $(SOLO_MUTATEE_DEFS) %s %s %s %s -o $@ -c $<\n"
						  % (compiler['defstring'], compiler['flags']['std'],
							 compiler['flags']['mutatee'],
							 compiler['abiflags'][platform['name']][abi],
							 compiler['optimization'][o]))
			if 'c++' in compiler['languages']:
				out.write("%%_mutatee_solo_%s_%s_%s.o: %%_solo_me.C\n"
						  % (info['compilers'][c]['executable'], abi, o))
				out.write("\t$(M_%s) $(SOLO_MUTATEE_DEFS) %s %s %s %s -o $@ -c $<\n"
						  % (compiler['defstring'], compiler['flags']['std'],
							 compiler['flags']['mutatee'],
							 compiler['abiflags'][platform['name']][abi],
							 compiler['optimization'][o]))
				out.write("%%_%s_%s_%s.o: ../src/%%.C\n" % (info['compilers'][c]['executable'], abi, o))
				out.write("\t$(M_%s) $(SOLO_MUTATEE_DEFS) %s %s %s %s -o $@ -c $<\n"
						  % (compiler['defstring'], compiler['flags']['std'],
							 compiler['flags']['mutatee'],
							 compiler['abiflags'][platform['name']][abi],
							 compiler['optimization'][o]))
	out.write("\n")

def write_make_solo_mutatee_gen(filename, tuplefile):
	read_tuples(tuplefile)
	compilers = info['compilers']
	mutatees = info['mutatees']
	out = open(filename, "w")
	print_mutatee_comp_defs(out)
	comps = collect_mutatee_comps(mutatees)
	pname = os.environ.get('PLATFORM')
	platform = find_platform(pname)
	for c in comps:
		muts = filter(lambda x: x['compiler'] == c, mutatees)
		print_mutatee_rules(out, muts, compilers[c])
		# Print rules for exceptional object files
		print_special_object_rules(c, out)
		print_generic_rules(c, out)
		out.write("# Rules for building the driver and utility objects\n")
		# TODO Replace this code generation with language neutral code
		# generation
		if 'c' in info['compilers'][c]['languages']:
			for abi in platform['abis']:
				out.write("mutatee_driver_solo_%s_%s.o: ../src/mutatee_driver.c\n" % (info['compilers'][c]['executable'], abi))
				out.write("\t$(M_%s) %s %s %s -o $@ -c $<\n"
						  % (compilers[c]['defstring'],
							 compilers[c]['flags']['std'],
							 compilers[c]['flags']['mutatee'],
							 compilers[c]['abiflags'][platform['name']][abi]))
				out.write("mutatee_util_%s_%s.o: ../src/mutatee_util.c\n"
						  % (info['compilers'][c]['executable'], abi))
				out.write("\t$(M_%s) %s %s %s -o $@ -c $<\n\n"
						  % (compilers[c]['defstring'],
							 compilers[c]['flags']['std'],
							 compilers[c]['flags']['mutatee'],
							 compilers[c]['abiflags'][platform['name']][abi]))
		else:
			out.write("# (Skipped: driver and utility objects cannot be compiled with this compiler\n")

	# Pattern rules for all compilers supported on this platform
	# TODO Make this handle all the auxilliary compiler for this platform
	# I think we want a pattern rule for each compiler at each optimization
	# level
	out.write("\n# Generic rules for this platform's auxilliary compilers\n\n")
	aux_comps = platform['auxilliary_compilers']
	for ac_lang in aux_comps:
		compname = aux_comps[ac_lang]
		comp = info['compilers'][compname]
		# TODO print pattern rule(s) for this compiler
		# ac should be a map from a language to a compiler..
		lang = filter(lambda l: l['name'] == ac_lang, info['languages'])[0]
		for ext in lang['extensions']:
			for abi in platform['abis']:
				for o in comp['optimization']:
					# FIXME Make this read the object extension from the
					# platform tuple
					out.write("%%_%s_%s_%s.o: ../src/%%%s\n"
							  % (compname, abi,	o, ext))
					# FIXME Make this read the parameter flags from the
					# compiler tuple (output file parameter flag)
					out.write("\t$(M_%s) %s %s %s -o $@ %s %s $<\n\n"
							  % (comp['defstring'],
								 comp['flags']['std'],
								 comp['flags']['mutatee'],
								 comp['abiflags'][platform['name']][abi],
								 comp['parameters']['partial_compile'],
								 comp['optimization'][o]))
# 	langs = map(lambda l: l['name'], info['languages'])
# 	for l in filter(lambda l: compiler_count(l) == 1, langs):
# 		# Print (a) pattern rule(s) for each of these languages
# 		comp = filter(lambda c: l in info['compilers'][c]['languages'],
# 					  info['compilers'])[0]
# 		# FIXME I really want a map here instead of this ugly lookup
# 		lang = filter(lambda x: x['name'] == l, info['languages'])[0]
# 		for e in lang['extensions']:
# 			# Print a pattern rule for this extension
# 			# FIXME Make this read the object extension from platform tuple
# 			out.write("%%.o: ../src/%%%s\n" % (e))
# 			# FIXME Make this read the parameter flags from compiler tuple
# 			out.write("\t%s %s -o $@ %s $<\n\n" % (comp, info['compilers'][comp]['flags']['std'], info['compilers'][comp]['parameters']['partial_compile']))

	# Also want to generate rules for any non-standard objects built with
	# auxilliary compilers..
	# Need to find the difference aux_comps \ comps..
	for l in aux_comps:
		c = platform['auxilliary_compilers'][l]
		if c not in comps:
			print_special_object_rules(c, out)

	# Now generate the rule for source munging and a rule to build all of the
	# mutatees
	# FIXME I need to rewrite the @<groupable>@ entity differently depending
	# on which test I'm rewriting..
 	out.write("# Generate the source file we'll use from user-written test source\n")
 	out.write("# and generic boilerplate\n")
	# Rungroups are labelled as groupable or not..  They also map to a single
	# mutatee each, so I can find the groupable and non-groupable rungroups,
	# and then extract mutatee names from them for use building these thingys
 	ng_sources = uniq(map(lambda m: m['preprocessed_sources'][0],
						  filter(lambda m: m['name'] != 'none'
								 and m['groupable'] == 'false',
								 info['mutatees'])))
 	g_sources = uniq(map(lambda m: m['preprocessed_sources'][0],
						 filter(lambda m: m['name'] != 'none'
								and m['groupable'] == 'true',
								info['mutatees'])))
 	for sourcefile in ng_sources:
 		# I need to match the boilerplate filename with the extension of the
 		# source file
		ext = extension(sourcefile)
		boilerplate = "solo_mutatee_boilerplate" + ext
		basename = sourcefile[0:-len('_mutatee') - len(ext)]
		out.write(".INTERMEDIATE: %s_solo_me%s # Temporary file\n"
				  % (basename, ext))
		out.write("%s_solo_me%s: ../src/%s\n" % (basename, ext, sourcefile))
		out.write("\tsed -e 's/@<testname>@/%s/g' -e 's/@<groupable>@/0/' < ../src/%s > $@\n" % (basename, boilerplate))
		out.write("\tcat $^ >> $@\n\n")
	for sourcefile in g_sources:
		ext = extension(sourcefile)
		boilerplate = "solo_mutatee_boilerplate" + ext
		basename = sourcefile[0:-len('_mutatee') - len(ext)]
		out.write(".INTERMEDIATE: %s_solo_me%s # Temporary file\n"
				  % (basename, ext))
		out.write("%s_solo_me%s: ../src/%s\n" % (basename, ext, sourcefile))
		out.write("\tsed -e 's/@<testname>@/%s/g' -e 's/@<groupable>@/1/' < ../src/%s > $@\n" % (basename, boilerplate))
		out.write("\tcat $^ >> $@\n\n")
	# What's up with these next few lines?  Which files do they deal with that
	# are neither in ng_sources or g_sources?
	out.write("%_solo_me.c: ../src/%_mutatee.c\n")
	out.write("\tsed -e 's/@<testname>@/$*/g' -e 's/@<groupable>@/0/' < ../src/solo_mutatee_boilerplate.c > $@\n")
	out.write("\tcat $^ >> $@\n\n")
	out.write("%_solo_me.C: ../src/%_mutatee.C\n")
	out.write("\tsed -e 's/@<testname>@/$*/g' -e 's/@<groupable>@/0/' < ../src/solo_mutatee_boilerplate.C > $@\n")
	out.write("\tcat $^ >> $@\n\n")
	out.write("# And a rule to build all of the mutatees\n")
	out.write(".PHONY: solo_mutatees\n")
	out.write("solo_mutatees: ")
	for c in comps:
		out.write("$(SOLO_MUTATEES_%s) " % (compilers[c]['defstring']))
	out.write("\n\n")
	out.write(".PHONY: clean_solo_mutatees\n")
	out.write("clean_solo_mutatees:\n")
	for c in comps:
		out.write("\t-$(RM) $(SOLO_MUTATEES_%s)\n"
				  % (compilers[c]['defstring']))
	# Get a list of optimization levels we're using and delete the mutatee
	# objects for each of them individually
	objExt = platform['filename_conventions']['object_suffix']
	for o in ['none', 'low', 'high', 'max']:
		out.write("\t-$(RM) *_%s%s\n" % (o, objExt))
	out.write("\n\n")
	out.write("SOLO_MUTATEES =")
	for c in comps:
		out.write(" $(SOLO_MUTATEES_%s)" % (compilers[c]['defstring']))
	out.write("\n\n")

	out.write("### COMPILER_CONTROL_DEFS is used to determine which compilers are present\n")
	out.write("### when compiling the list of mutatees to test against\n")
	out.write("COMPILER_CONTROL_DEFS =\n")
	for c in comps:
		if info['compilers'][c]['presencevar'] != 'true':
			out.write("ifdef %s # Is %s present?\n" % (info['compilers'][c]['presencevar'], c))
			out.write("COMPILER_CONTROL_DEFS += -D%s\n" % (info['compilers'][c]['presencevar']))
			out.write("endif\n")
	out.write('\n')
	
	out.close()
#
##########
